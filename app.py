import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from datetime import timedelta
import io

# --- ç¶²é è¨­å®š ---
st.set_page_config(page_title="CRM æ™ºæ…§ç”¢å“é æ¸¬ç³»çµ±", page_icon="ğŸ§ ", layout="wide")

# ==========================================
# ğŸ§  æ ¸å¿ƒå‡ç´š: æ™ºæ…§æ¬„ä½å°ç…§è¡¨ (æ–°å¢å®¢æˆ¶æ¬„ä½)
# ==========================================
COLUMN_MAPPING = {
    'date': [
        'å–®æ“šæ—¥æœŸ', 'ä¸‹å–®æ—¥', 'æ—¥æœŸ', 'éŠ·è²¨æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ', 'è¨‚å–®æ—¥æœŸ', 
        'Date', 'Order Date', 'Txn Date'
    ],
    'qty': [
        'æ•¸é‡', 'è¨‚å–®æ•¸é‡', 'éŠ·è²¨æ•¸é‡', 'å¯¦éš›å‡ºè²¨æ•¸é‡', 'Qty', 'Quantity', 
        'Amount', 'éŠ·å”®æ•¸é‡', 'å‡ºè²¨æ•¸é‡'
    ],
    'product': [
        'ç”¢å“ç·¨è™Ÿ', 'å“è™Ÿ', 'å“å', 'æ–™è™Ÿ', 'Product ID', 'Item Code', 
        'Part Number', 'ç”¢å“åç¨±', 'å•†å“ä»£ç¢¼'
    ],
    'customer': [
        'å®¢æˆ¶', 'å®¢æˆ¶ä»£è™Ÿ', 'å®¢æˆ¶ç°¡ç¨±', 'å®¢æˆ¶åç¨±', 'Customer', 'Client', 
        'Cust ID', 'Cust Name', 'Buyer'
    ]
}

def find_column(df, target_type):
    """æ™ºæ…§å°‹æ‰¾æ¬„ä½åç¨±"""
    candidates = COLUMN_MAPPING.get(target_type, [])
    # 1. ç²¾ç¢ºæ¯”å°
    for col in df.columns:
        if str(col).strip() in candidates:
            return col
    # 2. æ¨¡ç³Šæ¯”å°
    for col in df.columns:
        for candidate in candidates:
            if candidate in str(col):
                return col
    return None

# ==========================================
# ğŸ“¦ åŠŸèƒ½ 1: ç”Ÿæˆæ¨™æº–ç¯„æœ¬ (åŒ…å«å››å¤§è®Šæ•¸)
# ==========================================
def generate_example_file():
    output = io.BytesIO()
    # å»ºç«‹åŒ…å«å®Œæ•´ç¶­åº¦çš„ç¯„ä¾‹
    data = {
        'å®¢æˆ¶ä»£è™Ÿ': ['C001', 'C001', 'C002', 'C001', 'C002'],
        'ç”¢å“ç·¨è™Ÿ': ['P-1001', 'P-1001', 'P-1001', 'P-2002', 'P-2002'],
        'å–®æ“šæ—¥æœŸ': ['2023.01.15', '2023.02.20', '2023.04.10', '2023.06.05', '2024.01.12'],
        'æ•¸é‡': [100, 150, 200, 120, 300]
    }
    df_example = pd.DataFrame(data)
    
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df_example.to_excel(writer, index=False, sheet_name='éŠ·å”®æ˜ç´°è¡¨')
        
        # åŠ å…¥æ ¼å¼èªªæ˜
        workbook = writer.book
        worksheet = writer.sheets['éŠ·å”®æ˜ç´°è¡¨']
        worksheet.set_column('A:D', 15)
        
    output.seek(0)
    return output.getvalue()

def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='é æ¸¬çµæœ')
        try:
            worksheet = writer.sheets['é æ¸¬çµæœ']
            for i, col in enumerate(df.columns):
                col_len = max(df[col].astype(str).map(len).max(), len(col)) + 2
                worksheet.set_column(i, i, col_len)
        except:
            pass
    output.seek(0)
    return output.getvalue()

# ==========================================
# ğŸ” åŠŸèƒ½ 2: è³‡æ–™é æª¢èˆ‡çµæ§‹åŒ– (Audit Phase)
# ==========================================
def audit_and_process_data(uploaded_file):
    """
    è®€å–æª”æ¡ˆï¼Œåµæ¸¬æ¬„ä½ï¼Œä¸¦å°‡è³‡æ–™è½‰æ›ç‚ºçµ±ä¸€çš„ {key: dataframe} æ ¼å¼
    å›å‚³: (ç‹€æ…‹è¨Šæ¯, è™•ç†å¾Œçš„è³‡æ–™å­—å…¸, åµæ¸¬åˆ°çš„æ¬„ä½è³‡è¨Š)
    """
    try:
        raw_sheets = pd.read_excel(uploaded_file, sheet_name=None)
    except Exception as e:
        return f"âŒ æª”æ¡ˆè®€å–éŒ¯èª¤: {e}", None, None

    processed_dict = {}
    audit_info = {
        "total_rows": 0,
        "detected_columns": {},
        "grouping_mode": "æœªçŸ¥",
        "groups_found": 0
    }

    for sheet_name, df in raw_sheets.items():
        if df.empty: continue
        
        # 1. åµæ¸¬æ¬„ä½
        col_date = find_column(df, 'date')
        col_qty = find_column(df, 'qty')
        col_prod = find_column(df, 'product')
        col_cust = find_column(df, 'customer')
        
        if not col_date or not col_qty:
            continue
            
        audit_info["detected_columns"] = {
            "æ—¥æœŸ": col_date, "æ•¸é‡": col_qty, 
            "ç”¢å“": col_prod if col_prod else "(æœªåµæ¸¬åˆ° - ä½¿ç”¨åˆ†é å)",
            "å®¢æˆ¶": col_cust if col_cust else "(æœªåµæ¸¬åˆ° - è¦–ç‚ºå–®ä¸€å®¢æˆ¶)"
        }
        
        # æ¨™æº–åŒ–æ¬„ä½å
        rename_map = {col_date: 'date', col_qty: 'æ•¸é‡'}
        if col_prod: rename_map[col_prod] = 'product_id'
        if col_cust: rename_map[col_cust] = 'customer_id'
        
        df = df.rename(columns=rename_map)
        
        # 2. è³‡æ–™åˆ†çµ„é‚è¼¯ (Grouping Logic)
        if col_prod and col_cust:
            # æ¨¡å¼ A: å®¢æˆ¶ + ç”¢å“ (æœ€ç²¾æº–)
            audit_info["grouping_mode"] = "ç²¾æº–æ¨¡å¼ (å®¢æˆ¶ + ç”¢å“)"
            grouped = df.groupby(['customer_id', 'product_id'])
            for (cid, pid), sub_df in grouped:
                key = (str(cid).strip(), str(pid).strip()) # Key ç‚º Tuple
                processed_dict[key] = sub_df
                
        elif col_prod:
            # æ¨¡å¼ B: åƒ…ç”¢å“ (å¿½ç•¥å®¢æˆ¶å·®ç•°)
            audit_info["grouping_mode"] = "ç”¢å“æ¨¡å¼ (æ··åˆæ‰€æœ‰å®¢æˆ¶)"
            grouped = df.groupby('product_id')
            for pid, sub_df in grouped:
                key = ("å…¨éƒ¨å®¢æˆ¶", str(pid).strip())
                processed_dict[key] = sub_df
                
        else:
            # æ¨¡å¼ C: åƒ…åˆ†é  (èˆŠæ¨¡å¼)
            audit_info["grouping_mode"] = "ç°¡æ˜“æ¨¡å¼ (ä»¥åˆ†é ç‚ºç”¢å“)"
            key = ("é è¨­", sheet_name)
            processed_dict[key] = df

        audit_info["total_rows"] += len(df)

    audit_info["groups_found"] = len(processed_dict)
    
    if not processed_dict:
        return "âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ [æ—¥æœŸ] èˆ‡ [æ•¸é‡] æ¬„ä½ï¼Œè«‹æª¢æŸ¥ Excelã€‚", None, None
        
    return "OK", processed_dict, audit_info

# ==========================================
# ğŸ¤– åŠŸèƒ½ 3: AI é æ¸¬åŸ·è¡Œ (Prediction Phase)
# ==========================================
def run_prediction_engine(processed_data):
    final_summary = []
    
    # å»ºç«‹é€²åº¦æ¢
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(processed_data)
    count = 0

    for (cust_id, prod_id), df in processed_data.items():
        count += 1
        if count % max(1, int(total/20)) == 0:
            progress_bar.progress(int((count / total) * 100))
            status_text.text(f"åˆ†æä¸­... {cust_id} - {prod_id}")

        # --- ä»¥ä¸‹é‚è¼¯èˆ‡ v5 æ ¸å¿ƒç›¸åŒ ---
        # A. æ¸…æ´—
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['æ•¸é‡'] = pd.to_numeric(df['æ•¸é‡'], errors='coerce')
        df = df[df['æ•¸é‡'] > 0].dropna(subset=['date', 'æ•¸é‡']).sort_values('date').reset_index(drop=True)
        if df.empty: continue

        # B. åˆä½µè¨‚å–® (7å¤©)
        df['temp_gap'] = df['date'].diff().dt.days.fillna(999)
        df['session_id'] = (df['temp_gap'] > 7).cumsum()
        df = df.groupby('session_id').agg({'date': 'last', 'æ•¸é‡': 'sum'}).reset_index(drop=True)
        if len(df) < 2: continue

        # C. ç‰¹å¾µ
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['days_since_last'] = df['date'].diff().dt.days.fillna(0)
        df['rolling_days'] = df['days_since_last'].rolling(3, min_periods=1).mean()
        df['rolling_qty'] = df['æ•¸é‡'].rolling(3, min_periods=1).mean()
        df['target_days'] = df['date'].shift(-1).diff().dt.days.shift(-1)
        df['target_qty'] = df['æ•¸é‡'].shift(-1)

        train_df = df.dropna(subset=['target_days', 'target_qty']).copy()
        if len(train_df) >= 3: # é™ä½é–€æª»ï¼Œæœ‰3ç­†å°±è·‘
            train_df = train_df[train_df['year'] >= 2022] # åªå–è¿‘æœŸ
            if len(train_df) < 3: train_df = df.tail(10) # è‹¥ç¯©å®Œå¤ªå°‘ï¼Œç”¨å…¨éƒ¨

        features = ['æ•¸é‡', 'days_since_last', 'month', 'rolling_days', 'rolling_qty']
        last_row = df.tail(1).copy()
        sample_count = len(train_df)

        # D. æ··åˆé æ¸¬
        if sample_count < 5:
            p_days_1 = df['days_since_last'].median()
            p_qty_1 = df['æ•¸é‡'].median()
            conf_label = "ä½ (çµ±è¨ˆä¸­ä½æ•¸)"
        else:
            try:
                model_d = RandomForestRegressor(n_estimators=100, random_state=42)
                model_q = RandomForestRegressor(n_estimators=100, random_state=42)
                model_d.fit(train_df[features], train_df['target_days'])
                model_q.fit(train_df[features], train_df['target_qty'])
                p_days_1 = model_d.predict(last_row[features])[0]
                p_qty_1 = model_q.predict(last_row[features])[0]
                conf_label = "é«˜ (AI æ¨¡å‹)"
            except:
                p_days_1 = df['days_since_last'].median()
                p_qty_1 = df['æ•¸é‡'].median()
                conf_label = "ä½ (æ¨¡å‹éŒ¯èª¤è½‰çµ±è¨ˆ)"

        # E. ç´„æŸ
        max_gap = max(df['days_since_last'].max(), 30) * 1.5
        p_days_1 = max(1, int(min(p_days_1, 540, max_gap)))
        p_qty_1 = max(1, int(p_qty_1))

        date_1 = last_row['date'].iloc[0] + timedelta(days=p_days_1)
        date_2 = date_1 + timedelta(days=p_days_1) # T+2 ç°¡åŒ–æ¨ä¼°

        final_summary.append({
            'å®¢æˆ¶åç¨±': cust_id,
            'ç”¢å“ç·¨è™Ÿ': prod_id,
            'åˆ†æä¿¡å¿ƒåº¦': conf_label,
            'æœ€å¾Œä¸‹å–®æ—¥': last_row['date'].iloc[0].strftime('%Y-%m-%d'),
            'ã€é æ¸¬1ã€‘æ—¥æœŸ': date_1.strftime('%Y-%m-%d'),
            'ã€é æ¸¬1ã€‘æ•¸é‡': p_qty_1,
            'ã€é æ¸¬2ã€‘æ—¥æœŸ': date_2.strftime('%Y-%m-%d'),
            'æ­·å²æ¨£æœ¬æ•¸': sample_count
        })

    progress_bar.empty()
    status_text.empty()
    
    if final_summary:
        return pd.DataFrame(final_summary)
    return None

# ==========================================
# ğŸ–¥ï¸ ç¶²é ä¸»ä»‹é¢
# ==========================================
def main():
    st.title("ğŸ§  CRM æ™ºæ…§ç”¢å“é æ¸¬ç³»çµ± (v6)")
    st.caption("æ”¯æ´ï¼šå®¢æˆ¶åˆ†ç¾¤é æ¸¬ â€¢ è³‡æ–™è¦æ ¼é æª¢ â€¢ æ™ºæ…§æ¬„ä½åµæ¸¬")

    # --- å´é‚Šæ¬„ï¼šç¯„æœ¬ä¸‹è¼‰ ---
    with st.sidebar:
        st.header("1. æº–å‚™è³‡æ–™")
        st.markdown("è«‹ä¸‹è¼‰ç¯„æœ¬ï¼Œä¸¦å¡«å…¥æ‚¨çš„éŠ·å”®æ•¸æ“šã€‚")
        ex_file = generate_example_file()
        st.download_button("ğŸ“¥ ä¸‹è¼‰æ¨™æº–ç¯„æœ¬ (.xlsx)", ex_file, "import_template.xlsx")
        st.markdown("---")
        st.info("**æ¬„ä½èªªæ˜**ï¼š\n- **å®¢æˆ¶/ç”¢å“**ï¼šç³»çµ±æœƒä¾æ­¤åˆ†çµ„ã€‚\n- **æ—¥æœŸ/æ•¸é‡**ï¼šæ ¸å¿ƒé æ¸¬è®Šæ•¸ã€‚")

    # --- ä¸»ç•«é¢ï¼šä¸Šå‚³èˆ‡æª¢æ ¸ ---
    st.header("2. ä¸Šå‚³èˆ‡æª¢æ ¸")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ Excel æª”æ¡ˆ", type=['xlsx'])

    if uploaded_file:
        # 1. åŸ·è¡Œè³‡æ–™é æª¢ (Data Audit)
        status, processed_data, audit_info = audit_and_process_data(uploaded_file)

        if status != "OK":
            st.error(status)
        else:
            # 2. é¡¯ç¤ºæª¢æ ¸å ±å‘Š (Confirmation UI)
            st.success("âœ… æª”æ¡ˆè®€å–æˆåŠŸï¼è«‹ç¢ºèªä»¥ä¸‹è³‡æ–™è¦æ ¼ï¼š")
            
            c1, c2, c3 = st.columns(3)
            c1.metric("ç¸½è³‡æ–™ç­†æ•¸", audit_info["total_rows"])
            c2.metric("åˆ†æçµ„åˆæ•¸ (å®¢æˆ¶xç”¢å“)", audit_info["groups_found"])
            c3.info(f"åµæ¸¬æ¨¡å¼ï¼š{audit_info['grouping_mode']}")

            with st.expander("ğŸ” æŸ¥çœ‹è©³ç´°æ¬„ä½åµæ¸¬çµæœ", expanded=True):
                st.json(audit_info["detected_columns"])
                st.markdown("å¦‚æœåµæ¸¬çµæœæ­£ç¢ºï¼Œè«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å§‹åˆ†æã€‚")

            # 3. åŸ·è¡Œåˆ†ææŒ‰éˆ•
            if st.button("ğŸš€ ç¢ºèªç„¡èª¤ï¼Œé–‹å§‹é æ¸¬åˆ†æ", type="primary"):
                result_df = run_prediction_engine(processed_data)
                
                if result_df is not None:
                    st.divider()
                    st.header("3. åˆ†æçµæœ")
                    st.success(f"å®Œæˆï¼å…±ç”¢å‡º {len(result_df)} ç­†é æ¸¬çµæœã€‚")
                    
                    # å‘ˆç¾çµæœè¡¨æ ¼
                    st.dataframe(result_df.head(), use_container_width=True)
                    
                    # ä¸‹è¼‰æŒ‰éˆ•
                    excel_data = convert_df_to_excel(result_df)
                    st.download_button(
                        "ğŸ“¥ ä¸‹è¼‰å®Œæ•´é æ¸¬å ±å‘Š (.xlsx)",
                        excel_data,
                        "prediction_summary_v6.xlsx",
                        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.warning("âš ï¸ åˆ†æå®Œæˆï¼Œä½†å› è³‡æ–™é‡ä¸è¶³ (æ¯çµ„éœ€è‡³å°‘ 2 ç­†äº¤æ˜“)ï¼Œæ²’æœ‰ç”¢å‡ºé æ¸¬çµæœã€‚")

if __name__ == "__main__":
    main()