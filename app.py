import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from datetime import timedelta
import io

# --- ç¶²é è¨­å®š ---
st.set_page_config(page_title="CRM æ™ºæ…§ç”¢å“é æ¸¬ç³»çµ±", page_icon="ğŸ§ ", layout="wide")

# ==========================================
# ğŸ§  æ ¸å¿ƒå‡ç´š: æ™ºæ…§æ¬„ä½å°ç…§è¡¨
# ==========================================
COLUMN_MAPPING = {
    'date': [
        'å–®æ“šæ—¥æœŸ', 'ä¸‹å–®æ—¥', 'æ—¥æœŸ', 'éŠ·è²¨æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ', 'è¨‚å–®æ—¥æœŸ', 
        'Date', 'Order Date', 'Txn Date'
    ],
    'qty': [
        'æ•¸é‡', 'è¨‚å–®æ•¸é‡', 'éŠ·è²¨æ•¸é‡', 'å¯¦éš›å‡ºè²¨æ•¸é‡', 'Qty', 'Quantity', 
        'Amount', 'éŠ·å”®æ•¸é‡', 'å‡ºè²¨æ•¸é‡'
    ],
    'product': [
        'ç”¢å“ç·¨è™Ÿ', 'å“è™Ÿ', 'å“å', 'æ–™è™Ÿ', 'Product ID', 'Item Code', 
        'Part Number', 'ç”¢å“åç¨±', 'å•†å“ä»£ç¢¼'
    ],
    'customer': [
        'å®¢æˆ¶', 'å®¢æˆ¶ä»£è™Ÿ', 'å®¢æˆ¶ç°¡ç¨±', 'å®¢æˆ¶åç¨±', 'Customer', 'Client'
    ]
}

def find_column(df, target_type):
    """æ™ºæ…§å°‹æ‰¾æ¬„ä½åç¨±"""
    candidates = COLUMN_MAPPING.get(target_type, [])
    # 1. ç²¾ç¢ºæ¯”å°
    for col in df.columns:
        if str(col).strip() in candidates:
            return col
    # 2. æ¨¡ç³Šæ¯”å°
    for col in df.columns:
        for candidate in candidates:
            if candidate in str(col):
                return col
    return None

# ==========================================
# ğŸ§¹ ERP è³‡æ–™æ¸…æ´—æ ¸å¿ƒ (æ–°å¢åŠŸèƒ½)
# ==========================================
def clean_messy_erp_file(uploaded_file):
    """
    å°ˆé–€è™•ç†æ ¼å¼è·‘æ‰çš„ ERP å ±è¡¨ (åˆ—å°æ ¼å¼è½‰ Excel)
    """
    try:
        # å˜—è©¦è®€å–ç‚º CSV (å¾ˆå¤š ERP åŒ¯å‡ºå…¶å¯¦æ˜¯ Tab åˆ†éš”æˆ–é€—è™Ÿåˆ†éš”)
        uploaded_file.seek(0)
        df_raw = pd.read_csv(uploaded_file, header=None)
    except:
        try:
            uploaded_file.seek(0)
            df_raw = pd.read_excel(uploaded_file, header=None)
        except:
            return None

    cleaned_rows = []
    current_date = None
    current_customer = None
    
    # ç¡¬ç·¨ç¢¼é—œéµæ¬„ä½ä½ç½® (åŸºæ–¼ prn34c.xls åˆ†æ)
    # ç”¢å“ç·¨è™Ÿé€šå¸¸åœ¨ç¬¬ 5 æ¬„ (Index 5)
    
    for i, row in df_raw.iterrows():
        # 1. åµæ¸¬æ—¥æœŸè¡Œ
        first_col = str(row[0]).strip()
        if "è¨‚å–®æ—¥æœŸ" in first_col:
            val = str(row[2]).strip() # æ—¥æœŸé€šå¸¸åœ¨ç¬¬ 3 æ¬„
            if val and val != 'nan':
                current_date = val.replace('.', '-') # è½‰æˆæ¨™æº–æ ¼å¼
            continue

        # 2. åµæ¸¬è³‡æ–™è¡Œ
        # åˆ¤æ–·ä¾æ“š: ç¬¬ 5 æ¬„æœ‰å€¼ï¼Œä¸”ä¸æ˜¯æ¨™é¡Œ
        if len(row) > 5:
            prod_id = str(row[5]).strip()
            if prod_id and prod_id != 'nan' and prod_id != "ç”¢å“ç·¨è™Ÿ":
                
                # è™•ç†å®¢æˆ¶ (å¡«è£œç©ºç™½)
                cust = str(row[0]).strip()
                if cust and cust != 'nan':
                    current_customer = cust
                
                # è™•ç†æ•¸é‡èˆ‡å–®åƒ¹ (æœ€å›°é›£çš„éƒ¨åˆ†ï¼šæ¬„ä½æœƒä½ç§»)
                # ç­–ç•¥ï¼šæ‰¾åˆ°ã€Œç”¢å“åç¨±ã€å¾Œé¢çš„ã€Œå–®ä½ã€æ¬„ä½ï¼Œæ•¸å€¼é€šå¸¸åœ¨å–®ä½å¾Œé¢
                unit_idx = -1
                prod_name_col = 9
                
                # å¾€å¾Œæ‰¾ã€Œå–®ä½ã€(é€šå¸¸æ˜¯æ–‡å­—ä¸”é•·åº¦çŸ­)
                if len(row) > prod_name_col:
                    for c in range(prod_name_col + 1, len(row)):
                        val = str(row[c]).strip()
                        # åˆ¤æ–·æ˜¯å¦ç‚ºæ•¸å­—
                        try:
                            float(val.replace(',', ''))
                            is_num = True
                        except:
                            is_num = False
                        
                        if val and val != 'nan' and not is_num:
                            unit_idx = c
                            break
                
                qty = 0.0
                
                if unit_idx != -1:
                    # æ”¶é›†å–®ä½å¾Œé¢çš„æ‰€æœ‰æ•¸å­—
                    nums = []
                    for c in range(unit_idx + 1, len(row)):
                        val = str(row[c]).strip()
                        try:
                            num = float(val.replace(',', ''))
                            nums.append(num)
                        except:
                            pass
                        if len(nums) >= 3: break 
                    
                    # å•Ÿç™¼å¼è¦å‰‡
                    if len(nums) >= 2:
                        qty = nums[1] # é€šå¸¸æ˜¯ [å–®åƒ¹, æ•¸é‡]
                    elif len(nums) == 1:
                        qty = nums[0]
                
                # æ’é™¤åˆè¨ˆè¡Œ
                if "åˆè¨ˆ" not in str(row.values) and "ç¸½è¨ˆ" not in str(row.values):
                    cleaned_rows.append({
                        'å–®æ“šæ—¥æœŸ': current_date,
                        'å®¢æˆ¶åç¨±': current_customer,
                        'ç”¢å“ç·¨è™Ÿ': prod_id,
                        'æ•¸é‡': qty
                    })

    if not cleaned_rows:
        return None
        
    return pd.DataFrame(cleaned_rows)

# ==========================================
# ğŸ“¦ è¼”åŠ©åŠŸèƒ½: ç¯„æœ¬èˆ‡ Excel è¼¸å‡º
# ==========================================
def generate_example_file():
    output = io.BytesIO()
    data = {
        'å–®æ“šæ—¥æœŸ': ['2023.01.15', '2023.02.20'],
        'å®¢æˆ¶åç¨±': ['å®¢æˆ¶A', 'å®¢æˆ¶A'],
        'ç”¢å“ç·¨è™Ÿ': ['P001', 'P001'],
        'æ•¸é‡': [100, 150]
    }
    df = pd.DataFrame(data)
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False)
    output.seek(0)
    return output.getvalue()

def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='é æ¸¬çµæœ')
        try:
            worksheet = writer.sheets['é æ¸¬çµæœ']
            for i, col in enumerate(df.columns):
                col_len = max(df[col].astype(str).map(len).max(), len(col)) + 2
                worksheet.set_column(i, i, col_len)
        except:
            pass
    output.seek(0)
    return output.getvalue()

# ==========================================
# ğŸ” è³‡æ–™é æª¢èˆ‡çµæ§‹åŒ– (æ•´åˆæ¸…æ´—é‚è¼¯)
# ==========================================
def audit_and_process_data(uploaded_file):
    # 1. å˜—è©¦ç›´æ¥è®€å– (æ¨™æº– Excel)
    try:
        raw_sheets = pd.read_excel(uploaded_file, sheet_name=None)
    except:
        # å¦‚æœè®€å¤±æ•—ï¼Œå¯èƒ½æ˜¯ CSV æˆ–äº‚ç¢¼æª”
        uploaded_file.seek(0)
        try:
            raw_sheets = {'Sheet1': pd.read_csv(uploaded_file)}
        except:
            raw_sheets = {} # è®€å–å¤±æ•—

    processed_dict = {}
    audit_info = {"total_rows": 0, "detected_columns": {}, "grouping_mode": "æœªçŸ¥", "groups_found": 0}
    
    # ğŸš© åˆ¤æ–·æ˜¯å¦éœ€è¦å•Ÿå‹•ã€ŒERP æ¸…æ´—æ¨¡å¼ã€
    # å¦‚æœè®€é€²ä¾†ç¬¬ä¸€æ¬„æœ‰å¾ˆå¤š NaNï¼Œæˆ–è€…æ‰¾ä¸åˆ°æ¨™é¡Œï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯è·‘æ‰çš„æ ¼å¼
    needs_cleaning = False
    
    # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœæ‰€æœ‰ Sheet éƒ½æ‰¾ä¸åˆ° 'date' å’Œ 'qty'ï¼Œå°±å‡è¨­éœ€è¦æ¸…æ´—
    valid_sheets = 0
    for _, df in raw_sheets.items():
        if find_column(df, 'date') and find_column(df, 'qty'):
            valid_sheets += 1
            
    if valid_sheets == 0:
        needs_cleaning = True
    
    if needs_cleaning:
        uploaded_file.seek(0)
        st.toast("åµæ¸¬åˆ°éæ¨™æº–æ ¼å¼ï¼Œæ­£åœ¨å•Ÿå‹• ERP æ¸…æ´—å¼•æ“...", icon="ğŸ§¹")
        df_cleaned = clean_messy_erp_file(uploaded_file)
        
        if df_cleaned is not None and not df_cleaned.empty:
            # æ¸…æ´—æˆåŠŸï¼Œå°‡å…¶è¦–ç‚ºæ¨™æº–è³‡æ–™ç¹¼çºŒè™•ç†
            raw_sheets = {'Cleaned_Data': df_cleaned}
        else:
            return "âŒ ç„¡æ³•è­˜åˆ¥æª”æ¡ˆæ ¼å¼ï¼Œä¸”è‡ªå‹•æ¸…æ´—å¤±æ•—ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ˜¯å¦ç‚ºæ”¯æ´çš„ Excel/CSVã€‚", None, None

    # --- ä»¥ä¸‹é‚è¼¯èˆ‡æ¨™æº–åŒ–è™•ç†ç›¸åŒ ---
    for sheet_name, df in raw_sheets.items():
        if df.empty: continue
        
        col_date = find_column(df, 'date')
        col_qty = find_column(df, 'qty')
        col_prod = find_column(df, 'product')
        col_cust = find_column(df, 'customer')
        
        if not col_date or not col_qty: continue
            
        audit_info["detected_columns"] = {
            "æ—¥æœŸ": col_date, "æ•¸é‡": col_qty, 
            "ç”¢å“": col_prod, "å®¢æˆ¶": col_cust
        }
        
        rename_map = {col_date: 'date', col_qty: 'æ•¸é‡'}
        if col_prod: rename_map[col_prod] = 'product_id'
        if col_cust: rename_map[col_cust] = 'customer_id'
        df = df.rename(columns=rename_map)
        
        # åˆ†çµ„é‚è¼¯
        if col_prod and col_cust:
            audit_info["grouping_mode"] = "ç²¾æº–æ¨¡å¼ (å®¢æˆ¶ + ç”¢å“)"
            for (cid, pid), sub_df in df.groupby(['customer_id', 'product_id']):
                key = (str(cid).strip(), str(pid).strip())
                processed_dict[key] = sub_df
        elif col_prod:
            audit_info["grouping_mode"] = "ç”¢å“æ¨¡å¼"
            for pid, sub_df in df.groupby('product_id'):
                key = ("å…¨éƒ¨å®¢æˆ¶", str(pid).strip())
                processed_dict[key] = sub_df
        else:
            audit_info["grouping_mode"] = "ç°¡æ˜“æ¨¡å¼"
            key = ("é è¨­", sheet_name)
            processed_dict[key] = df
            
        audit_info["total_rows"] += len(df)

    audit_info["groups_found"] = len(processed_dict)
    if not processed_dict:
        return "âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆè³‡æ–™", None, None
        
    return "OK", processed_dict, audit_info

# ==========================================
# ğŸ¤– é æ¸¬å¼•æ“ (æ ¸å¿ƒé‚è¼¯)
# ==========================================
def run_prediction_engine(processed_data):
    final_summary = []
    progress_bar = st.progress(0)
    total = len(processed_data)
    count = 0

    for (cust_id, prod_id), df in processed_data.items():
        count += 1
        progress_bar.progress(int((count / total) * 100))

        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['æ•¸é‡'] = pd.to_numeric(df['æ•¸é‡'], errors='coerce')
        df = df[df['æ•¸é‡'] > 0].dropna(subset=['date', 'æ•¸é‡']).sort_values('date').reset_index(drop=True)
        if df.empty: continue

        # åˆä½µè¨‚å–® (7å¤©)
        df['temp_gap'] = df['date'].diff().dt.days.fillna(999)
        df['session_id'] = (df['temp_gap'] > 7).cumsum()
        df = df.groupby('session_id').agg({'date': 'last', 'æ•¸é‡': 'sum'}).reset_index(drop=True)
        if len(df) < 2: continue

        # ç‰¹å¾µå·¥ç¨‹
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['days_since_last'] = df['date'].diff().dt.days.fillna(0)
        df['target_days'] = df['date'].shift(-1).diff().dt.days.shift(-1)
        df['target_qty'] = df['æ•¸é‡'].shift(-1)
        
        train_df = df.dropna(subset=['target_days', 'target_qty']).copy()
        if len(train_df) >= 3:
            train_df = train_df[train_df['year'] >= 2022]
            if len(train_df) < 3: train_df = df.tail(10)

        last_row = df.tail(1).copy()
        
        # æ··åˆé æ¸¬ (AI + çµ±è¨ˆ)
        if len(train_df) < 5:
            p_days = df['days_since_last'].median()
            p_qty = df['æ•¸é‡'].median()
            conf = "ä½ (çµ±è¨ˆ)"
        else:
            try:
                model_d = RandomForestRegressor(n_estimators=100, random_state=42)
                model_d.fit(train_df[['æ•¸é‡', 'days_since_last', 'month']], train_df['target_days'])
                p_days = model_d.predict(last_row[['æ•¸é‡', 'days_since_last', 'month']])[0]
                p_qty = df['æ•¸é‡'].median() # ç°¡åŒ–æ•¸é‡é æ¸¬ä»¥æ±‚ç©©
                conf = "é«˜ (AI)"
            except:
                p_days = df['days_since_last'].median()
                p_qty = df['æ•¸é‡'].median()
                conf = "ä½ (éŒ¯èª¤)"

        p_days = max(1, int(p_days))
        date_1 = last_row['date'].iloc[0] + timedelta(days=p_days)
        
        final_summary.append({
            'å®¢æˆ¶åç¨±': cust_id, 'ç”¢å“ç·¨è™Ÿ': prod_id, 'åˆ†æä¿¡å¿ƒåº¦': conf,
            'æœ€å¾Œä¸‹å–®æ—¥': last_row['date'].iloc[0].strftime('%Y-%m-%d'),
            'ã€é æ¸¬1ã€‘æ—¥æœŸ': date_1.strftime('%Y-%m-%d'),
            'ã€é æ¸¬1ã€‘æ•¸é‡': int(p_qty),
            'æ­·å²è¨‚å–®æ•¸': len(df)
        })

    progress_bar.empty()
    if final_summary: return pd.DataFrame(final_summary)
    return None

# ==========================================
# ğŸ–¥ï¸ ç¶²é ä¸»ä»‹é¢
# ==========================================
def main():
    st.title("ğŸ§  CRM æ™ºæ…§ç”¢å“é æ¸¬ç³»çµ± (v7)")
    st.caption("æ”¯æ´åŠŸèƒ½ï¼šè‡ªå‹•æ¸…æ´— ERP å ±è¡¨ â€¢ å®¢æˆ¶åˆ†ç¾¤é æ¸¬ â€¢ æ™ºæ…§æ¬„ä½åµæ¸¬")

    with st.sidebar:
        st.header("1. æº–å‚™è³‡æ–™")
        ex_file = generate_example_file()
        st.download_button("ğŸ“¥ ä¸‹è¼‰æ¨™æº–ç¯„æœ¬", ex_file, "template.xlsx")
        st.info("ğŸ’¡ æç¤ºï¼šæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ä¸Šå‚³å¾ ERP åŒ¯å‡ºçš„åŸå§‹å ±è¡¨ (å¦‚ prn34c.xls)ï¼Œç³»çµ±æœƒè‡ªå‹•å˜—è©¦æ•´ç†æ ¼å¼ã€‚")

    st.header("2. ä¸Šå‚³èˆ‡æª¢æ ¸")
    uploaded_file = st.file_uploader("ä¸Šå‚³ Excel/CSV æª”æ¡ˆ", type=['xlsx', 'csv', 'xls'])

    if uploaded_file:
        status, processed_data, audit_info = audit_and_process_data(uploaded_file)

        if status != "OK":
            st.error(status)
        else:
            st.success("âœ… æª”æ¡ˆè®€å–æˆåŠŸï¼")
            
            # --- è³‡æ–™é è¦½èˆ‡ç¢ºèªå€ ---
            st.subheader("ğŸ§ è³‡æ–™é è¦½")
            c1, c2, c3 = st.columns(3)
            c1.metric("ç¸½è³‡æ–™ç­†æ•¸", audit_info["total_rows"])
            c2.metric("åˆ†æçµ„åˆæ•¸", audit_info["groups_found"])
            c3.info(f"æ¨¡å¼ï¼š{audit_info['grouping_mode']}")
            
            st.markdown("è«‹æª¢æŸ¥ä¸‹æ–¹çš„**ã€æ•¸é‡ã€‘**èˆ‡**ã€ç”¢å“ã€‘**æ˜¯å¦æ­£ç¢ºï¼š")
            
            # æŠ“å‡ºå‰ 5 ç­†é è¦½
            if processed_data:
                preview_list = []
                for k, df in list(processed_data.items())[:5]:
                    temp = df.head(2).copy()
                    temp['Group_Key'] = str(k)
                    preview_list.append(temp)
                if preview_list:
                    preview_df = pd.concat(preview_list)
                    st.dataframe(preview_df.head(10), use_container_width=True)

            if st.button("ğŸš€ ç¢ºèªç„¡èª¤ï¼Œé–‹å§‹é æ¸¬", type="primary"):
                result_df = run_prediction_engine(processed_data)
                if result_df is not None:
                    st.divider()
                    st.success(f"å®Œæˆï¼å…±ç”¢å‡º {len(result_df)} ç­†é æ¸¬ã€‚")
                    st.dataframe(result_df, use_container_width=True)
                    excel_data = convert_df_to_excel(result_df)
                    st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±å‘Š", excel_data, "prediction_v7.xlsx")
                else:
                    st.warning("âš ï¸ ç„¡æ³•ç”¢å‡ºçµæœ (å¯èƒ½åŸå› æ˜¯æ­·å²è³‡æ–™ä¸è¶³ï¼Œæ¯é …ç”¢å“éœ€è‡³å°‘ 2 ç­†äº¤æ˜“)ã€‚")

if __name__ == "__main__":
    main()